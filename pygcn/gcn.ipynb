{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"../data/cora\", dataset=\"cora\"):\n",
    "    print(f\"Loading {dataset} dataset...\")\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\n",
    "        f\"{path}/{dataset}.content\", dtype=np.dtype(str)\n",
    "    )\n",
    "    #     array([['31336', '0', '0', ..., '0', '0', 'Neural_Networks'],\n",
    "    #        ['1061127', '0', '0', ..., '0', '0', 'Rule_Learning'],\n",
    "    #        ['1106406', '0', '0', ..., '0', '0', 'Reinforcement_Learning'],\n",
    "    #        ...,\n",
    "    #        ['1128978', '0', '0', ..., '0', '0', 'Genetic_Algorithms'],\n",
    "    #        ['117328', '0', '0', ..., '0', '0', 'Case_Based'],\n",
    "    #        ['24043', '0', '0', ..., '0', '0', 'Neural_Networks']],dtype='<U22')\n",
    "    # idx_features_labels는 1:-1이 Features / -1이 Labels로 나타난다.\n",
    "    # Graph를 구축하기 위한 관계도는 .cites에 위치\n",
    "\n",
    "    # 각 Features를 csr_matrix(compressed Sparse Row Matrix)로 변환\n",
    "    # 각 Labels를 One Hot Encoding으로 변환\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # csr_matrix:\n",
    "    # coo_matrix: A sparse matrix in COOrdinate format\n",
    "\n",
    "    # Build Graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)  # index for papers\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}                # index의 순차적 index\n",
    "\n",
    "    edges_unordered = np.genfromtxt(\n",
    "        f\"{path}/{dataset}.cites\", dtype=np.int32\n",
    "    )                                                          # edges_unordered: 각 Paper가 가리키고 있는 Paper\n",
    "    edges = np.array(\n",
    "        list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32\n",
    "    ).reshape(edges_unordered.shape)                           # edges들을 고유 index가 아닌 개수에 맞는 index 변환\n",
    "    \n",
    "    \n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "    \n",
    "    # Build Symmetric Adjacency Matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "    # Normalize의 과정 속에 Degree의 -1/2승을 곱해주는 것이 있는데, 이를 위해\n",
    "    # 먼저 Adjacency Matrix A에 eye matrix를 더해주는 Renormalization Trick을 적용하는 것을 볼 수 있습니다.\n",
    "    \n",
    "    idx_train = range(140)            # Train은 0~140\n",
    "    idx_val = range(200, 500)         # Validation은 200~500\n",
    "    idx_test = range(500, 1500)       # Test 는 500~1500 Index를 가진 데이터\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "cuda = True\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    \n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    for idx in tqdm(range(epoch)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            model.eval()\n",
    "            output = model(features, adj)\n",
    "            loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "            acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "            print('Epoch: {:04d}'.format(epoch+1),\n",
    "                  'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                  'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [00:00<00:06, 161.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 1.9435 acc_train: 0.1643 loss_val: 1.9457 acc_val: 0.1267 time: 0.0099s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 134/1000 [00:00<00:04, 189.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.6612 acc_train: 0.8786 loss_val: 0.8939 acc_val: 0.7967 time: 0.5628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 232/1000 [00:01<00:04, 188.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.3778 acc_train: 0.9571 loss_val: 0.6816 acc_val: 0.8200 time: 1.0999s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 332/1000 [00:01<00:03, 193.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.3142 acc_train: 0.9500 loss_val: 0.6397 acc_val: 0.8167 time: 1.6282s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 433/1000 [00:02<00:02, 196.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.2661 acc_train: 0.9786 loss_val: 0.6239 acc_val: 0.8167 time: 2.1309s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 534/1000 [00:02<00:02, 196.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.2492 acc_train: 0.9571 loss_val: 0.6299 acc_val: 0.8133 time: 2.6476s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 637/1000 [00:03<00:01, 199.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.1953 acc_train: 0.9714 loss_val: 0.6175 acc_val: 0.8200 time: 3.1488s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 741/1000 [00:03<00:01, 199.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.1888 acc_train: 1.0000 loss_val: 0.6225 acc_val: 0.8267 time: 3.6470s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 825/1000 [00:04<00:00, 200.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.2102 acc_train: 0.9786 loss_val: 0.6208 acc_val: 0.8233 time: 4.1465s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 925/1000 [00:04<00:00, 180.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1001 loss_train: 0.2138 acc_train: 0.9714 loss_val: 0.6206 acc_val: 0.8100 time: 4.6878s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 190.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: loss= 0.6021 accuracy= 0.8330\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/cora\"\n",
    "dataset=\"cora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_features_labels = np.genfromtxt(f'{path}/{dataset}.content', dtype=np.dtype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array(idx_features_labels[:, 0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_map = {j:i for i, j in enumerate(idx)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_map.get(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_unordered = np.genfromtxt(f'{path}/{dataset}.cites', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     35,    1033,      35, ...,  853118,  954315, 1155073],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_unordered.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     35,    1033],\n",
       "       [     35,  103482],\n",
       "       [     35,  103515],\n",
       "       ...,\n",
       "       [ 853118, 1140289],\n",
       "       [ 853155,  853118],\n",
       "       [ 954315, 1155073]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(\n",
    "        list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32\n",
    "    ).reshape(edges_unordered.shape)\n",
    "    \n",
    "\n",
    "# Build Symmetric Adjacency Matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 163,  402],\n",
       "       [ 163,  659],\n",
       "       [ 163, 1696],\n",
       "       ...,\n",
       "       [1887, 2258],\n",
       "       [1902, 1887],\n",
       "       [ 837, 1686]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encode_onehot(idx_features_labels[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-973053c00cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         dtype=np.float32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edges' is not defined"
     ]
    }
   ],
   "source": [
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 5429 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_map.get(103482)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(\n",
    "        list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32\n",
    "    ).reshape(edges_unordered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    # adj: Adjacency Matrix\n",
    "    # x: Feature Matrix\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224w",
   "language": "python",
   "name": "cs224w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
